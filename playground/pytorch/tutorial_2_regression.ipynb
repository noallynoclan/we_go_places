{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torchviz -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchviz import make_dot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
    "\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "train_idx = idx[:80]\n",
    "val_idx = idx[80:]\n",
    "\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]\n",
    "\n",
    "plt.scatter(x_train, y_train);\n",
    "plt.scatter(x_val, y_val, c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/345/1*7fmJUcQT578OBfX7Q8hluQ.png\">\n",
    "<img src=\"https://miro.medium.com/max/850/1*YvTj1B-h1gzSI5F24OgrrA.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.02354094] [1.96896411]\n",
      "CPU times: user 32 ms, sys: 0 ns, total: 32 ms\n",
      "Wall time: 29.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(42)\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train\n",
    "    error = (y_train - yhat)\n",
    "    loss = (error ** 2).mean()\n",
    "    a_grad = -2 * error.mean()\n",
    "    b_grad = -2 * (x_train * error).mean()\n",
    "    a = a - lr * a_grad\n",
    "    b = b - lr * b_grad\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.02354075] [1.96896447]\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "linr = LinearRegression()\n",
    "linr.fit(x_train, y_train)\n",
    "print(linr.intercept_, linr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
      "CPU times: user 408 ms, sys: 40 ms, total: 448 ms\n",
      "Wall time: 435 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= lr * a.grad\n",
    "        b -= lr * b.grad\n",
    "    \n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 660 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "yhat = a + b * x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
      "CPU times: user 416 ms, sys: 36 ms, total: 452 ms\n",
      "Wall time: 437 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
      "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
      "CPU times: user 420 ms, sys: 28 ms, total: 448 ms\n",
      "Wall time: 432 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    \n",
    "    # No more manual loss!\n",
    "    # error = y_tensor - yhat\n",
    "    # loss = (error ** 2).mean()\n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a', tensor([0.3367], device='cuda:0')), ('b', tensor([0.1288], device='cuda:0'))])\n",
      "OrderedDict([('a', tensor([1.0235], device='cuda:0')), ('b', tensor([1.9690], device='cuda:0'))])\n",
      "CPU times: user 396 ms, sys: 44 ms, total: 440 ms\n",
      "Wall time: 424 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\n",
    "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.a + self.b * x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = ManualLinearRegression().to(device)\n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # What is this?!?\n",
    "    model.train()\n",
    "\n",
    "    # No more manual prediction!\n",
    "    # yhat = a + b * x_tensor\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a', tensor([1.0235], device='cuda:0')), ('b', tensor([1.9690], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "class LayerLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of our custom parameters, we use a Linear layer with single input and single output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Now it only takes a call to the layer to make predictions\n",
    "        return self.linear(x)\n",
    "    \n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def train_step(x, y):\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "        # Makes predictions\n",
    "        yhat = model(x)\n",
    "        # Computes loss\n",
    "        loss = loss_fn(y, yhat)\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "        # Updates parameters and zeroes gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return train_step\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # Performs one train step and returns the corresponding loss\n",
    "    loss = train_step(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)\n",
    "    \n",
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n",
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a', tensor([1.0287], device='cuda:0')), ('b', tensor([1.9715], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
    "        # therefore, we need to send those mini-batches to the\n",
    "        # device where the model \"lives\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a', tensor([1.0080], device='cuda:0')), ('b', tensor([1.9774], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "            val_loss = loss_fn(y_val, yhat)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
